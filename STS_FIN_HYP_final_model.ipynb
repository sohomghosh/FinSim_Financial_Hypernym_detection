{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS_FIN_HYP_final_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPskzrWWIWfyI3YVcjOGS+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohomghosh/FinSim_Financial_Hypernym_detection/blob/main/STS_FIN_HYP_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A2Gq3T-JThX"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mfjswGG62jg"
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sentence_transformers import SentenceTransformer, losses, SentencesDataset, evaluation, InputExample, util\n",
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJGgcxumJL0R"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg4EQBGDJhty"
      },
      "source": [
        "def compute_average_rank(Y_test, predictions):\n",
        "  ranks = []\n",
        "  for idx, y in enumerate(Y_test):\n",
        "    ranks.append(get_rank(Y_test[idx], predictions[idx]))\n",
        "  return np.mean(ranks)\n",
        "\n",
        "def get_rank(gold, list_predictions, max_k=3):\n",
        "  list_predictions = list_predictions[:max_k]\n",
        "  try:\n",
        "    rank = list_predictions.index(gold) + 1\n",
        "  except ValueError:\n",
        "    rank = max_k + 1\n",
        "  return rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWOJ245ze_cy"
      },
      "source": [
        "# Reading Augmented Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjagjrUyfIk5"
      },
      "source": [
        "NOTE: The original dataset has been provided by the organizers https://sites.google.com/nlg.csie.ntu.edu.tw/finnlp2021/shared-task-finsim\n",
        "\n",
        "This dataset has to be augmented with external data from <br>\n",
        "* Investopedia https://www.investopedia.com/financial-term-dictionary-4769738 <br>\n",
        "* FIBO https://spec.edmcouncil.org/fibo/OWL <br>\n",
        "* DBPedia https://lookup.dbpedia.org/api/search/?query=term (Replace term with each of the financial terms) <br>\n",
        "\n",
        "Details regarding the acronym detector module within Spacy is available at https://github.com/allenai/scispacy\n",
        "\n",
        "Due to copyright conatraints, we cannot release the augmented dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V5MQIENhLfG"
      },
      "source": [
        "my_dict = {\"Bonds\":0, \"Forward\":1, \"Funds\":2, \"Future\":3, \"MMIs\":4, \"Option\":5, \"Stocks\":6, \"Swap\":7, \"Equity Index\":8, \"Credit Index\":9, \"Regulatory Agency\":10, \"Central Securities Depository\":11, \"Stock Corporation\":12, \"Credit Events\":13, \"Debit procing and yields\":14, \"Parametric schedules\":15, \"Securities restrictions\":16}\n",
        "\n",
        "data_aug_train = pd.read_csv(\"data_aug_train.csv\")\n",
        "data_aug_valid = pd.read_csv(\"data_aug_valid.csv\") \n",
        "\n",
        "#  Each of the above files has 5 columns 'term', 'term_definition', 'label', 'label_definition' and 'label_text'. \n",
        "# 'term' and 'label' have been provided by the organizers\n",
        "# 'term_definition' and 'label_definition' have been obtained through the data augmentation steps\n",
        "# 'label_text' contains numeric mappings of 'labels' using the dictionary my_dict\n",
        "\n",
        "label_df = pd.read_csv(\"labels_definition.csv\") # It has 17 rows i.e. one for each label. It has 2 columns 'label' and 'label_definition'. 'label_definition' is the expanded form of 'label' and has been obtained fro FIBO & internet.\n",
        "label_df_new = label_def.copy()\n",
        "label_df_new['label_text'] = label_def['label'].apply(lambda x : my_dict[x])\n",
        "label_df_new = label_df_new.sort_values('label_text').copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUkSA9Ti8Qs"
      },
      "source": [
        "# Storing hierarchy of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpVEceO1jXdX"
      },
      "source": [
        "level0_dict = {\"Bonds\":\"SEC\", \"MMIs\":\"SEC\", \"Stocks\":\"SEC\", \"Securities restrictions\":\"SEC\", \"Parametric schedules\":\"SEC\",\n",
        "          \"Forward\":\"DER\", \"Option\":\"DER\", \"Swap\": \"DER\",\n",
        "          \"Future\" :\"FBC\", \"Credit Events\":\"FBC\", \"Central Securities Depository\":\"FBC\", \"Regulatory Agency\":\"FBC\",\n",
        "         \"Equity Index\":\"IND\",\"Credit Index\":\"IND\",\n",
        "         \"Funds\":\"CIV\",\n",
        "        \"Debt pricing and yields\":\"MD\",\n",
        "        \"Stock Corporation\":\"BE\"}\n",
        "\n",
        "level1_dict= {\"Bonds\":\"Debt\", \"MMIs\":\"Debt\", \"Stocks\":\"Equities\", \"Securities restrictions\":\"Securities\", \"Parametric schedules\":\"Securities\",\n",
        "          \"Forward\":\"Derivatives Contracts\", \"Option\":\"Derivatives Contracts\", \"Swap\": \"Derivatives Contracts\",\n",
        "          \"Future\" :\"Financial Instruments\", \"Credit Events\":\"Debts and equities\", \"Central Securities Depository\":\"Functional Entities\", \"Regulatory Agency\":\"Functional Entities\",\n",
        "         \"Equity Index\":\"Market Indices\",\n",
        "        \"Credit Index\":\"Market Indices\",\n",
        "         \"Funds\":\"Funds\",\n",
        "        \"Debt pricing and yields\":\"Debt Temporal\",\n",
        "        \"Stock Corporation\":\"Legal Entities\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmOfwDNtjNoq"
      },
      "source": [
        "# Algorithm to generate negative samples from existing training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUajKA6bjnHK"
      },
      "source": [
        "k = 0.4\n",
        "sent1_li, sent2_li, label_li = [], [], []\n",
        "for train_sent, label_sent, label, term in zip(data_aug_train['term_definition'].values, data_aug_train['label_definition'].values, data_aug_train['label'].values, data_aug_train['term'].values):\n",
        "  sent1_li.append(train_sent)\n",
        "  sent2_li.append(label_sent)\n",
        "  label_li.append(1.0)\n",
        "\n",
        "  lvl0 = level0_dict[label]\n",
        "  lvl1 = level1_dict[label]\n",
        "\n",
        "  rnd_df = data_aug_train[(data_aug_train['term']!=term) & (data_aug_train['label']!=label)].sample(10, random_state = 42)\n",
        "  for new_train_sent, new_label_sent, new_label, new_term in zip(rnd_df['term_definition'].values, rnd_df['label_definition'].values, rnd_df['label'].values, rnd_df['term'].values):\n",
        "    lvl0_new = level0_dict[new_label]\n",
        "    lvl1_new = level1_dict[new_label]\n",
        "    if lvl1 == lvl1_new:\n",
        "      sent1_li.append(train_sent)\n",
        "      sent2_li.append(new_label_sent)\n",
        "      label_li.append(2*k)\n",
        "    elif lvl0 == lvl0_new:\n",
        "      sent1_li.append(train_sent)\n",
        "      sent2_li.append(new_label_sent)\n",
        "      label_li.append(k)\n",
        "    else:\n",
        "      sent1_li.append(train_sent)\n",
        "      sent2_li.append(new_label_sent)\n",
        "      label_li.append(0.0)\n",
        "\n",
        "data_pos_neg = pd.DataFrame({'term_or_def': sent1_li, 'label_or_def':sent2_li, 'sim':label_li})\n",
        "data_pos_neg['sim'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFzHcJ4eirmE"
      },
      "source": [
        "# Undersampling to balance the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krgSfJoSiu1b"
      },
      "source": [
        "N = 1400\n",
        "data_pos_neg_use = data_pos_neg[data_pos_neg['sim'] > 0].append(data_pos_neg[data_pos_neg['sim'] == 0].sample(N, random_state=42)).copy().fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hinV2h6miU-6"
      },
      "source": [
        "# Model-1 using FinBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v-U28EMiVLQ"
      },
      "source": [
        "model1 = SentenceTransformer('ProsusAI/finbert')\n",
        "model_save_path = 'finbert_fin_hyp'\n",
        "train_batch_size = 20\n",
        "num_epochs = 25\n",
        "\n",
        "distance_metric = losses.SiameseDistanceMetric.COSINE_DISTANCE\n",
        "margin = 0.5\n",
        "\n",
        "train_samples_MultipleNegativesRankingLoss = []\n",
        "train_samples_ConstrativeLoss = []\n",
        "\n",
        "for sent1,sent2,sim in zip(data_pos_neg_use['term_or_def'].values, data_pos_neg_use['label_or_def'].values, data_pos_neg_use['sim'].values):\n",
        "    train_samples_ConstrativeLoss.append(InputExample(texts=[sent1, sent2], label=sim))\n",
        "    if sim == 1.0:\n",
        "        train_samples_MultipleNegativesRankingLoss.append(InputExample(texts=[sent1, sent2], label=sim))\n",
        "        train_samples_MultipleNegativesRankingLoss.append(InputExample(texts=[sent1, sent2], label=sim))  # if A is a duplicate of B, then B is a duplicate of A\n",
        "\n",
        "# Create data loader and loss for MultipleNegativesRankingLoss\n",
        "train_dataset_MultipleNegativesRankingLoss = SentencesDataset(train_samples_MultipleNegativesRankingLoss, model=model1)\n",
        "train_dataloader_MultipleNegativesRankingLoss = DataLoader(train_dataset_MultipleNegativesRankingLoss, shuffle=True, batch_size=train_batch_size)\n",
        "train_loss_MultipleNegativesRankingLoss = losses.MultipleNegativesRankingLoss(model1)\n",
        "\n",
        "\n",
        "# Create data loader and loss for OnlineContrastiveLoss\n",
        "train_dataset_ConstrativeLoss = SentencesDataset(train_samples_ConstrativeLoss, model=model1)\n",
        "train_dataloader_ConstrativeLoss = DataLoader(train_dataset_ConstrativeLoss, shuffle=True, batch_size=train_batch_size)\n",
        "train_loss_ConstrativeLoss = losses.OnlineContrastiveLoss(model=model1, distance_metric=distance_metric, margin=margin)\n",
        "\n",
        "# .....\n",
        "# Train the model\n",
        "model1.fit(train_objectives=[(train_dataloader_MultipleNegativesRankingLoss, train_loss_MultipleNegativesRankingLoss), (train_dataloader_ConstrativeLoss, train_loss_ConstrativeLoss)],\n",
        "          #evaluator=seq_evaluator,\n",
        "          epochs=num_epochs,\n",
        "          warmup_steps=1000,\n",
        "          output_path=model_save_path\n",
        "          )\n",
        "model1.save('./'+model_save_path+\"_save\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WGWUcfFiQSw"
      },
      "source": [
        "# Model-2 using FinISH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m-4nCIBhjNP"
      },
      "source": [
        "model2 = SentenceTransformer(\"yseop/roberta-base-finance-hypernym-identification\")\n",
        "model_save_path = 'finbert_fin_hyp'\n",
        "train_batch_size = 30\n",
        "num_epochs = 45\n",
        "\n",
        "distance_metric = losses.SiameseDistanceMetric.COSINE_DISTANCE\n",
        "margin = 0.5\n",
        "\n",
        "train_samples_MultipleNegativesRankingLoss = []\n",
        "train_samples_ConstrativeLoss = []\n",
        "\n",
        "for sent1,sent2,sim in zip(data_pos_neg_use['term_or_def'].values, data_pos_neg_use['label_or_def'].values, data_pos_neg_use['sim'].values):\n",
        "    train_samples_ConstrativeLoss.append(InputExample(texts=[sent1, sent2], label=sim))\n",
        "        if sim == 1.0:\n",
        "            train_samples_MultipleNegativesRankingLoss.append(InputExample(texts=[sent1, sent2], label=sim))\n",
        "            train_samples_MultipleNegativesRankingLoss.append(InputExample(texts=[sent1, sent2], label=sim))  # if A is a duplicate of B, then B is a duplicate of A\n",
        "\n",
        "# Create data loader and loss for MultipleNegativesRankingLoss\n",
        "train_dataset_MultipleNegativesRankingLoss = SentencesDataset(train_samples_MultipleNegativesRankingLoss, model=model2)\n",
        "train_dataloader_MultipleNegativesRankingLoss = DataLoader(train_dataset_MultipleNegativesRankingLoss, shuffle=True, batch_size=train_batch_size)\n",
        "train_loss_MultipleNegativesRankingLoss = losses.MultipleNegativesRankingLoss(model2)\n",
        "\n",
        "\n",
        "# Create data loader and loss for OnlineContrastiveLoss\n",
        "train_dataset_ConstrativeLoss = SentencesDataset(train_samples_ConstrativeLoss, model=model2)\n",
        "train_dataloader_ConstrativeLoss = DataLoader(train_dataset_ConstrativeLoss, shuffle=True, batch_size=train_batch_size)\n",
        "train_loss_ConstrativeLoss = losses.OnlineContrastiveLoss(model=model2, distance_metric=distance_metric, margin=margin)\n",
        "\n",
        "# .....\n",
        "# Train the model\n",
        "model2.fit(train_objectives=[(train_dataloader_MultipleNegativesRankingLoss, train_loss_MultipleNegativesRankingLoss), (train_dataloader_ConstrativeLoss, train_loss_ConstrativeLoss)],\n",
        "          evaluator=seq_evaluator,\n",
        "          epochs=num_epochs,\n",
        "          warmup_steps=1000,\n",
        "          output_path=model_save_path\n",
        "          )\n",
        "model2.save('./'+model_save_path+\"_save\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s37NCzeCicvN"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMVDqeSyiiOw"
      },
      "source": [
        "corpus = list(label_df_new['label_definition'].values)\n",
        "\n",
        "# Query sentences:\n",
        "queries = list(data_aug_valid['term_definition'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydaCEDaH5_8F"
      },
      "source": [
        "def results_pred(model):\n",
        "\n",
        "  corpus_embedding = model.enocde(corpus, convert_to_tensor=True)\n",
        "\n",
        "  top_k = min(17, len(corpus))\n",
        "  all_hits = []\n",
        "  for query in queries:\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=17)\n",
        "    all_hits.append(hits)\n",
        "\n",
        "    lli = []\n",
        "    for kk in all_hits:\n",
        "      kk_trns = {}\n",
        "      for i in kk[0]:\n",
        "        kk_trns[i['corpus_id']] = i['score']\n",
        "      lli.append([kk_trns[i] for i in range(17)])\n",
        "\n",
        "    valid_y = list(data_aug_valid['label_text'].values)\n",
        "\n",
        "    predicted_df = pd.DataFrame({'term' : list(data_aug_valid['term'].values), 'label':valid_y})\n",
        "    predicted_df = pd.concat([predicted_df, pd.DataFrame(lli)], axis = 1)\n",
        "\n",
        "    pddf = predicted_df.groupby(['term', 'label']).mean().reset_index()\n",
        "    pddf['li'] = pddf[[i for i in range(17)]].values.tolist()\n",
        "\n",
        "    pddf['pred_valid'] = [np.argmax(i) for i in pddf['li'].values]\n",
        "    pddf['predictions_to_rank'] = [list(np.argsort(i)[::-1]) for  i in pddf['li'].values]\n",
        "    print(compute_average_rank(list(pddf['label']),list(ppdf['predictions_to_rank'])), accuracy_score(list(pddf['label']), list(pddf['pred_valid'])))\n",
        "    return pddf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVqSMu4BijPc"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SENxp0zHiliL"
      },
      "source": [
        "results_v1 = results_pred(model1)\n",
        "results_v2 = results(model2)\n",
        "\n",
        "cols = ['term', 'label', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
        "\n",
        "ensembled_df = results_v1[cols].append(results_v2[cols]).reset_index()\n",
        "ensembled_pddf = ensembled_df.groupby(['term', 'label']).mean().reset_index()\n",
        "ensembled_pddf['li'] = ensembled_pddf[[i for i in range(17)]].values.tolist()\n",
        "\n",
        "ensembled_pddf['pred_valid'] = [np.argmax(i) for i in ensembled_pddf['li'].values]\n",
        "ensembled_pddf['predictions_to_rank'] = [list(np.argsort(i)[::-1]) for i in ensembled_pddf['li'].values]\n",
        "print(compute_average_rank(list(ensembled_pddf['label']),list(ensembled_ppdf['predictions_to_rank'])), accuracy_score(list(ensembled_pddf['label']), list(ensembled_pddf['pred_valid'])))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
